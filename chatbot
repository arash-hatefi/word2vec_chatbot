{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instruction on Running the Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Download Word2Vec from [this link](https://drive.google.com/u/0/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM&export=download)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Add the path to Word2Vec file in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete before running ...\n",
    "\n",
    "WORD2VEC_PATH = ...\n",
    "CORPUS_PATH = \"./processed_dataset.txt\"\n",
    "STOP_WORDS_FILE_PATH = \"./StopWords.txt\"\n",
    "\n",
    "REMOVE_STOP_WORDS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Run the entire notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Loading Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD2VEC = gensim.models.KeyedVectors.load_word2vec_format(WORD2VEC_PATH, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load the Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stop_words(path):\n",
    "    with open(path) as f:\n",
    "        words = f.readlines()\n",
    "    return [word.rstrip('\\n|\\t| ') for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = load_stop_words(STOP_WORDS_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Implementing the Dialogue and Corpus Classes for Processing and Storing the Dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dialogue:\n",
    "    \n",
    "    __STOP_WORDS = set(STOP_WORDS)\n",
    "    \n",
    "    def __init__(self, query, response, remove_stop_words):\n",
    "        \n",
    "        self.__query = query\n",
    "        self.__response = response\n",
    "        self.__words_in_query = list(filter(None, re.split(\"[\\ ,;\\.\\?\\!]\", query.lower())))\n",
    "        self.__remove_stop_words = remove_stop_words\n",
    "        self.__word2vec_average = self.__compute_word2vec_average()  \n",
    "    \n",
    "    def __compute_word2vec_average(self):\n",
    "        \n",
    "        vectors = []\n",
    "        for word in self.__words_in_query:\n",
    "            try:\n",
    "                if not self.__remove_stop_words:\n",
    "                    vectors.append(WORD2VEC[word])\n",
    "                elif not word in self.__STOP_WORDS: \n",
    "                    vectors.append(WORD2VEC[word])\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        if (vectors): \n",
    "            word2vec_average = np.mean(np.array(vectors), axis=0)\n",
    "            return word2vec_average/np.linalg.norm(word2vec_average)\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    \n",
    "    def is_valied(self): return not(type(self.__word2vec_average)==type(None))\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def query(self): return self.__query\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def response(self): return self.__response\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def words_in_query(self): return self.__words_in_query\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def word2vec_average(self): return self.__word2vec_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus:\n",
    "    \n",
    "    \n",
    "    def __init__(self, queries, responses, remove_stop_words):\n",
    "        \n",
    "        self.__queries = queries\n",
    "        self.__responses = responses\n",
    "        self.__dialogues = [Dialogue(query, response, remove_stop_words) for (query, response) in zip(self.__queries, self.__responses)]\n",
    "        self.__dialogues = list(filter(lambda dialogue: dialogue.is_valied(), self.__dialogues))\n",
    "        self.__word2vec_averages = np.array([dialogue.word2vec_average for dialogue in self.__dialogues])\n",
    "        self.__remove_stop_words = remove_stop_words\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def queries(self): return self.__queries\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def responses(self): return self.__responses \n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def dialogues(self): return self.__dialogues \n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def word2vec_averages(self): return self.__word2vec_averages\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def remove_stop_words(self): return self.__remove_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_corpus_from_text(corpus_path, remove_stop_words):\n",
    "    \n",
    "    with open(corpus_path, encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "    queries, responses = [], []\n",
    "    for line in lines:\n",
    "        query, response = line.split('\\t')\n",
    "        queries.append(query)\n",
    "        responses.append(response)        \n",
    "    return Corpus(queries, responses, remove_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Implementing the Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotInput(Dialogue):\n",
    "    \n",
    "    \n",
    "    def __init__(self, query, remove_stop_words):\n",
    "        \n",
    "        super().__init__(query, \"\", remove_stop_words)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chatbot:\n",
    "    \n",
    "    __INPUT_ERROR_MESSAGE = \"Sorry I didn't understant what you said\"\n",
    "    __DEFAULT_NUMBER_OF_MATCHES = 1\n",
    "    \n",
    "    def __init__(self, corpus):\n",
    "        \n",
    "        self.__corpus = corpus\n",
    "            \n",
    "    \n",
    "    def run(self):\n",
    "        \n",
    "        counter = 1\n",
    "        while (True):\n",
    "            print(f\"\\nIn{counter}: \", end='')\n",
    "            input_sentence = input()\n",
    "            if input_sentence:  print(f\"Out{counter}: {self.__get_oputput(input_sentence)}\")\n",
    "            counter += 1\n",
    "    \n",
    "    \n",
    "    def __get_oputput(self, input_sentence):\n",
    "        \n",
    "        chatbot_input = ChatbotInput(input_sentence, self.__corpus.remove_stop_words)\n",
    "        if (chatbot_input.is_valied()):\n",
    "            most_similar_dialogues = self.__get_similar_dialogues(chatbot_input, self.__DEFAULT_NUMBER_OF_MATCHES)\n",
    "            random_idx = random.randint(0, self.__DEFAULT_NUMBER_OF_MATCHES-1)\n",
    "            return most_similar_dialogues[random_idx].response\n",
    "        else:\n",
    "            return self.__INPUT_ERROR_MESSAGE\n",
    "    \n",
    "    \n",
    "    def __get_similar_dialogues(self, chatbot_input, n):\n",
    "        \n",
    "        cosine_similarities = self.__get_cosine_similarities(chatbot_input)\n",
    "        cosine_similarities_and_dialogues = list(zip(corpus.dialogues, cosine_similarities))\n",
    "        sorted_cosine_similarities_and_dialogues = sorted(cosine_similarities_and_dialogues, key=lambda x: x[1], reverse=True)\n",
    "        most_similar_dialogues = [dialogues for (dialogues, cosine_similarities)in sorted_cosine_similarities_and_dialogues[:n]]\n",
    "        return most_similar_dialogues\n",
    "    \n",
    "    \n",
    "    def __get_cosine_similarities(self, chatbot_input):\n",
    "        \n",
    "        return np.dot(chatbot_input.word2vec_average, corpus.word2vec_averages.T)\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def corpus(self): return self.__corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Building the Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = build_corpus_from_text(CORPUS_PATH, REMOVE_STOP_WORDS)\n",
    "chatbot = Chatbot(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Running the Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In1: Hello\n",
      "Out1:  Hello, Is that Stefan?\n",
      "\n",
      "\n",
      "In2: No. It is arash\n",
      "Out2:  Oh, I'm sorry.\n",
      "\n",
      "\n",
      "In3: How are you\n",
      "Out3:  Fine, and you?\n",
      "\n",
      "\n",
      "In4: sdgfdsfdsfsdf\n",
      "Out4: Sorry I didn't understant what you said\n",
      "\n",
      "In5: How is the weather\n",
      "Out5:  It stops snowing, but there's a bit wind.\n",
      "\n",
      "\n",
      "In6: Do you enjoy the weather?\n",
      "Out6:  I heard it might rain.\n",
      "\n",
      "\n",
      "In7: Why do you hate the weather?\n",
      "Out7:  I don't like the weather like this. Cold and rainy. Hope it become sunny as soon as possible.\n",
      "\n",
      "\n",
      "In8: I hate the weather too\n",
      "Out8:  Well, it won't last long.\n",
      "\n",
      "\n",
      "In9: good to here that we are going to have some sunny days\n",
      "Out9:  Thank you. I am a learner so can you tell me where I can find a ski instructor?\n",
      "\n",
      "\n",
      "In10: I don't know\n",
      "Out10:  You have to pay a fine.\n",
      "\n",
      "\n",
      "In11: "
     ]
    }
   ],
   "source": [
    "chatbot.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
